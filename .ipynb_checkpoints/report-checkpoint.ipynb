{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h1>Self-Driving Agent Report</h1>\n",
    "\n",
    "<h2>1. Implementation of a Basic Driving Agent</h2>\n",
    "\n",
    "As starting task, we will move the smartcab around the environment using a random approach. The set of possible actions will be: None, forward, left, right. The deadline will be set to false, but this doesn't mean that smartcab has an infinite number of moves as can see on code of the file **smartcab/environment.py** (but will increase a lot the number of moves available).\n",
    "\n",
    "The code corresponding to this agent can be found on the class **RandomAgent** at the file **smartcab/agents.py**.\n",
    "\n",
    "Observations from simulation:\n",
    "\n",
    "1. Normally the smartcab action is not optimal, but normally reaches the destination because has a lot of moves available to reach the destination.\n",
    "2. The environment  doesn't allow any agent to execute and action that violates traffic rules, but a strong negative reward is applied.\n",
    "\n",
    "<h2>2. Inform the Driving Agent</h2>\n",
    "\n",
    "The next task  is to identify a set of states that are appropriate for modeling the smartcab and environment. \n",
    "\n",
    "All the information we receive come from the environment and the planner.\n",
    "\n",
    "Sensing the environment provide us with these inputs:\n",
    "\n",
    "- light:\n",
    "    - Possible values: Red / Green\n",
    "- oncoming:\n",
    "    - Possible values: None / Forward / Right / Left\n",
    "    - Indicates if there is a car oncoming and the action wants to execute.\n",
    "- right:\n",
    "    - Possible values: None / Forward / Right / Left\n",
    "    - Indicates if there is a car approaching from the right oncoming and \n",
    "    the action wants to execute.\n",
    "- left:\n",
    "    - Possible values: None / Forward / Right / Left\n",
    "    - Indicates if there is a car approaching from the left oncoming and \n",
    "    the action wants to execute.\n",
    "\n",
    "Also from the environment we can obtain the deadline, that is the number of remaining moves to reach the destination.\n",
    "\n",
    "The planner provides next_waypoint, with these possible values: Forward, Right and Left.\n",
    "\n",
    "For representing the state we will use: **next_waypoint**, **light**, **oncoming**, **right** and **left**.\n",
    "\n",
    "Having in mind we use *next_waypoint*, is not very useful to also use *deadline*. Also *deadline* will increase considerably the number of possible states, and would penalize the Q-Learning implementation.\n",
    "\n",
    "The information from *light*, *oncoming*, *right* and *left* can help Q-Learning to avoid traffic violations. The information from *next_waypoint* can help Q-Learning to reach the destination as soon as possible.\n",
    " \n",
    "Having in mind the properties used for the state, and possible values for each of these, the total number of different states are: 3 x 2 x 4 x 4 x 4. This means a total of 384 states at a given time.\n",
    "\n",
    "<h2>3. Implement a Q-Learning Driving Agent</h2>\n",
    "\n",
    "The third task is to implement the Q-Learning algorithm for the driving agent. The code corresponding to this agent can be found on the class **QLearningAgent** at the file **smartcab/agents.py**.\n",
    "\n",
    "The core of the algorithm is a simple value iteration update. It assumes the old value and makes a correction based on the new information (Source: [Wikipedia](https://en.wikipedia.org/wiki/Q-learning)):\n",
    "\n",
    "![](images/qlearn.png)\n",
    "\n",
    "Before proceeding to the simulation, some parameter values should be set.\n",
    "\n",
    "In the formula shown above, two contants can be seen:\n",
    "- **alpha_rate (α)** or **learning rate**: Determines to what extent the newly acquired information will override the old information.\n",
    "- **gamma rate (γ)** or **discount factor**: Determines the importance of future rewards.\n",
    "\n",
    "I will start with **alpha_rate = 0.9** and **gamma rate = 0.5**.\n",
    "\n",
    "Another important value is the **epsilon_rate (ε)** or **exploration rate**, that determines when to explore or when to exploit the already learn information. I will start with **epsilon_rate = 0.1**.\n",
    "\n",
    "Finally Q values should have an initial value. I will  use **0.0 as initial value**. Please notice that in the corresponding code I don't make a static initialization. Instead in the method **get_q_value** I return **self.q_init_value==0.0** that is equivalent:\n",
    "\n",
    "~~~~\n",
    "def get_q_value(self, state, action):\n",
    "    key = (state, action)\n",
    "    return self.q_matrix.get(key, self.q_init_value)\n",
    "~~~~\n",
    "\n",
    "The reason is that I've added code to build stats, and one of the values i want to track is the number of explored states. I get this number by simply using this code:\n",
    "\n",
    "~~~~\n",
    "len(self.q_matrix)\n",
    "~~~~\n",
    "\n",
    "The simulation will be executed 100 times, with enforce_deadline to True.\n",
    "\n",
    "The stats data has been stored in a file that I will analyze below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"smartcab/stats_first_qlearn_agent.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **data** dataframe is a table containing 100 rows (one by simulation iteration), and 5 columns:\n",
    "- **simulation_round**: The round number of the simulation.\n",
    "- **success**: True if the agent reached the destination.\n",
    "- **cum_reward**: The accumulated reward in that simulation.\n",
    "- **explored_states_cum**: The accumulated number of states explored.\n",
    "- **traffic_violations_count**: The traffic violations that occurred in that simulation.\n",
    "- **actions_count**: The actions taken in that simulation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Let's explore the 10 first iterations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>simulation_round</th>\n",
       "      <th>success</th>\n",
       "      <th>cum_reward</th>\n",
       "      <th>explored_states_cum</th>\n",
       "      <th>traffic_violations_count</th>\n",
       "      <th>actions_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>-3.5</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>7.5</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>6.0</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>-7.5</td>\n",
       "      <td>24</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>19.0</td>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>True</td>\n",
       "      <td>0.5</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>11.5</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>True</td>\n",
       "      <td>4.0</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "      <td>10.5</td>\n",
       "      <td>31</td>\n",
       "      <td>7</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   simulation_round success  cum_reward  explored_states_cum  \\\n",
       "0                 1    True        -3.5                    8   \n",
       "1                 2   False        -7.0                   20   \n",
       "2                 3   False         7.5                   21   \n",
       "3                 4   False         6.0                   22   \n",
       "4                 5    True        -7.5                   24   \n",
       "5                 6    True        19.0                   26   \n",
       "6                 7    True         0.5                   27   \n",
       "7                 8    True        11.5                   28   \n",
       "8                 9    True         4.0                   29   \n",
       "9                10    True        10.5                   31   \n",
       "\n",
       "   traffic_violations_count  actions_count  \n",
       "0                        10             20  \n",
       "1                        10             51  \n",
       "2                         3             26  \n",
       "3                         0             31  \n",
       "4                         7             20  \n",
       "5                         2             27  \n",
       "6                         1              3  \n",
       "7                         2             10  \n",
       "8                         0             10  \n",
       "9                         7             31  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the 10 first simulations the success is \n",
    "\n",
    "We can see that normally don't reachs the destination. We can see that the number of states explored increases as iterations are done. And we can see that normally do a lot of traffic violations.\n",
    "\n",
    "Let's see now the 10 last iterations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>simulation_round</th>\n",
       "      <th>success</th>\n",
       "      <th>cum_reward</th>\n",
       "      <th>explored_states_cum</th>\n",
       "      <th>traffic_violations_count</th>\n",
       "      <th>actions_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>91</td>\n",
       "      <td>False</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>83</td>\n",
       "      <td>8</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>92</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>93</td>\n",
       "      <td>False</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>83</td>\n",
       "      <td>5</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>94</td>\n",
       "      <td>False</td>\n",
       "      <td>-3.5</td>\n",
       "      <td>83</td>\n",
       "      <td>9</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>95</td>\n",
       "      <td>True</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>83</td>\n",
       "      <td>9</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96</td>\n",
       "      <td>False</td>\n",
       "      <td>3.5</td>\n",
       "      <td>83</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97</td>\n",
       "      <td>True</td>\n",
       "      <td>3.0</td>\n",
       "      <td>83</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98</td>\n",
       "      <td>True</td>\n",
       "      <td>9.0</td>\n",
       "      <td>83</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99</td>\n",
       "      <td>False</td>\n",
       "      <td>15.0</td>\n",
       "      <td>83</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100</td>\n",
       "      <td>False</td>\n",
       "      <td>17.0</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    simulation_round success  cum_reward  explored_states_cum  \\\n",
       "90                91   False        -4.5                   83   \n",
       "91                92   False         0.0                   83   \n",
       "92                93   False        -2.0                   83   \n",
       "93                94   False        -3.5                   83   \n",
       "94                95    True        -1.0                   83   \n",
       "95                96   False         3.5                   83   \n",
       "96                97    True         3.0                   83   \n",
       "97                98    True         9.0                   83   \n",
       "98                99   False        15.0                   83   \n",
       "99               100   False        17.0                   83   \n",
       "\n",
       "    traffic_violations_count  actions_count  \n",
       "90                         8             26  \n",
       "91                         0             26  \n",
       "92                         5             41  \n",
       "93                         9             21  \n",
       "94                         9             25  \n",
       "95                         8             21  \n",
       "96                         2              8  \n",
       "97                         3             16  \n",
       "98                         1             26  \n",
       "99                         0             31  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We see more or less the same behaviour that in the first iterations, so we can conclude that *QLearningAgent* is \n",
    "not learning well.\n",
    "\n",
    "\n",
    "\n",
    "Let's see the number of times that the *QLearningAgent* has been successful:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\n"
     ]
    }
   ],
   "source": [
    "print len(data[(data.success)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *QLearningAgent* has a 38% of success.\n",
    "\n",
    "I've done 100 simulations with the *RandomAgent* and *enforce_deadline=True*, and it has a 16% of success."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>4. Improve the Q-Learning Driving Agent</h2>\n",
    "\n",
    "Now let's tune the values for the **Q init value**, the **learning rate (alpha)**, **the discount factor (gamma)** and the **exploration rate (epsilon)**.\n",
    "\n",
    "We will use *Grid Search* technique to tune these parameters. First I will do a **grosso modo** Grid Search, and the I will do a second **fine tuned** Grid Search.\n",
    "\n",
    "<h3>4.1. First (grosso modo) Grid Search</h3>\n",
    "\n",
    "I will do a first grid search with these range of values:\n",
    "- *q_init_values*: 0.0, 5.0, 10 (3 values)\n",
    "- *alpha_rate*: 0.00, 0.25, 0.50, 0.75, 1.00 (5 values)\n",
    "- *epsilon_rate*: 0.00, 0.25, 0.50, 0.75, 1.00 (5 values)\n",
    "- *gamma_rate*: 0.00, 0.25, 0.50, 0.75, 1.00 (5 values)\n",
    "\n",
    "The total of combinations will be 375 (3x5x5x5). For each of the combinations, we will perform 100 simulations. This means 37.500 simulations will be done.\n",
    "\n",
    "The results of the simulations will be stored on a csv file, that we will analyze.\n",
    "\n",
    "The correspoding code used to generate this data can be found on **smartcab/main_qlearn_agent_tuning.py**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from altair import Chart\n",
    "\n",
    "tuning_data = pd.read_csv(\"smartcab/qlearn_agent_tuning_results.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Let's see some sample rows to understand the data contained:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q_init_value</th>\n",
       "      <th>alpha_rate</th>\n",
       "      <th>epsilon_rate</th>\n",
       "      <th>gamma_rate</th>\n",
       "      <th>success_perc</th>\n",
       "      <th>traffic_violations_avg</th>\n",
       "      <th>explored_states_avg</th>\n",
       "      <th>reward_cum_avg</th>\n",
       "      <th>actions_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>20.0</td>\n",
       "      <td>7.1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>-3.60</td>\n",
       "      <td>26.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.1</td>\n",
       "      <td>29.8</td>\n",
       "      <td>-2.30</td>\n",
       "      <td>29.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.6</td>\n",
       "      <td>29.9</td>\n",
       "      <td>-3.15</td>\n",
       "      <td>34.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.3</td>\n",
       "      <td>25.2</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>29.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.2</td>\n",
       "      <td>30.9</td>\n",
       "      <td>-0.85</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   q_init_value  alpha_rate  epsilon_rate  gamma_rate  success_perc  \\\n",
       "0           0.0         0.0           0.0        0.00          20.0   \n",
       "1           0.0         0.0           0.0        0.25          10.0   \n",
       "2           0.0         0.0           0.0        0.50           0.0   \n",
       "3           0.0         0.0           0.0        0.75          10.0   \n",
       "4           0.0         0.0           0.0        1.00          10.0   \n",
       "\n",
       "   traffic_violations_avg  explored_states_avg  reward_cum_avg  actions_avg  \n",
       "0                     7.1                 28.0           -3.60         26.9  \n",
       "1                     7.1                 29.8           -2.30         29.5  \n",
       "2                     8.6                 29.9           -3.15         34.5  \n",
       "3                     7.3                 25.2           -0.10         29.2  \n",
       "4                     6.2                 30.9           -0.85         28.0  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuning_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each row corresponds to a simulation. The columns are:\n",
    "- **q_init_value**: The Q initial value used in that simulation.\n",
    "- **alpha_rate**: The alpha rate value used in that simulation.\n",
    "- **epsilon_rate**: The epsilon rate value used in that simulation.\n",
    "- **gamma_rate**: The gamma rate value used in that simulation.\n",
    "- **success_perc**: The percentage of success in that simulation.\n",
    "- **traffic_violations_avg**: The traffic violation on average in that simulation.\n",
    "- **explored_states_avg**: The explored states on average in that simulation.\n",
    "- **reward_cum_avg**: The accumulated reward on average in that simulation.\n",
    "- **actions_avg**: The actions done on average in that simulation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After doing this first **grosso modo** grid search, we will do a second **fine tuned** grid search. But first we need to determine what an optimal policy for our problem can be.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h3>4.2. An optimal policy</h3>\n",
    "\n",
    "In my opinion an optimal policy for the smartcab is one that (in order of importance):\n",
    "1. Minimizes the number of traffic violations.\n",
    "2. Maximizes the success.\n",
    "3. Minimizes the number of actions taken."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "So let's start describing the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q_init_value</th>\n",
       "      <th>alpha_rate</th>\n",
       "      <th>epsilon_rate</th>\n",
       "      <th>gamma_rate</th>\n",
       "      <th>success_perc</th>\n",
       "      <th>traffic_violations_avg</th>\n",
       "      <th>explored_states_avg</th>\n",
       "      <th>reward_cum_avg</th>\n",
       "      <th>actions_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>375.000000</td>\n",
       "      <td>375.000000</td>\n",
       "      <td>375.000000</td>\n",
       "      <td>375.000000</td>\n",
       "      <td>375.000000</td>\n",
       "      <td>375.000000</td>\n",
       "      <td>375.000000</td>\n",
       "      <td>375.000000</td>\n",
       "      <td>375.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>21.120000</td>\n",
       "      <td>6.990667</td>\n",
       "      <td>28.638400</td>\n",
       "      <td>-1.677067</td>\n",
       "      <td>27.040000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.087937</td>\n",
       "      <td>0.354026</td>\n",
       "      <td>0.354026</td>\n",
       "      <td>0.354026</td>\n",
       "      <td>14.764606</td>\n",
       "      <td>1.746239</td>\n",
       "      <td>2.818525</td>\n",
       "      <td>2.809958</td>\n",
       "      <td>3.565626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>18.200000</td>\n",
       "      <td>-7.850000</td>\n",
       "      <td>16.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>26.800000</td>\n",
       "      <td>-3.400000</td>\n",
       "      <td>24.850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>7.200000</td>\n",
       "      <td>28.400000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>27.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>8.100000</td>\n",
       "      <td>30.300000</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>29.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>11.400000</td>\n",
       "      <td>37.400000</td>\n",
       "      <td>12.650000</td>\n",
       "      <td>35.800000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       q_init_value  alpha_rate  epsilon_rate  gamma_rate  success_perc  \\\n",
       "count    375.000000  375.000000    375.000000  375.000000    375.000000   \n",
       "mean       5.000000    0.500000      0.500000    0.500000     21.120000   \n",
       "std        4.087937    0.354026      0.354026    0.354026     14.764606   \n",
       "min        0.000000    0.000000      0.000000    0.000000      0.000000   \n",
       "25%        0.000000    0.250000      0.250000    0.250000     10.000000   \n",
       "50%        5.000000    0.500000      0.500000    0.500000     20.000000   \n",
       "75%       10.000000    0.750000      0.750000    0.750000     30.000000   \n",
       "max       10.000000    1.000000      1.000000    1.000000     80.000000   \n",
       "\n",
       "       traffic_violations_avg  explored_states_avg  reward_cum_avg  \\\n",
       "count              375.000000           375.000000      375.000000   \n",
       "mean                 6.990667            28.638400       -1.677067   \n",
       "std                  1.746239             2.818525        2.809958   \n",
       "min                  1.000000            18.200000       -7.850000   \n",
       "25%                  6.000000            26.800000       -3.400000   \n",
       "50%                  7.200000            28.400000       -2.000000   \n",
       "75%                  8.100000            30.300000       -0.500000   \n",
       "max                 11.400000            37.400000       12.650000   \n",
       "\n",
       "       actions_avg  \n",
       "count   375.000000  \n",
       "mean     27.040000  \n",
       "std       3.565626  \n",
       "min      16.800000  \n",
       "25%      24.850000  \n",
       "50%      27.000000  \n",
       "75%      29.600000  \n",
       "max      35.800000  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuning_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The minimum value for *traffic_violations_avg* is 1.00, this is a really good average.\n",
    "\n",
    "Let's look for rows where *traffic_violations_avg <= 5* and *success_perc >= 80*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q_init_value</th>\n",
       "      <th>alpha_rate</th>\n",
       "      <th>epsilon_rate</th>\n",
       "      <th>gamma_rate</th>\n",
       "      <th>success_perc</th>\n",
       "      <th>traffic_violations_avg</th>\n",
       "      <th>explored_states_avg</th>\n",
       "      <th>reward_cum_avg</th>\n",
       "      <th>actions_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>25.6</td>\n",
       "      <td>7.55</td>\n",
       "      <td>22.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    q_init_value  alpha_rate  epsilon_rate  gamma_rate  success_perc  \\\n",
       "50           0.0         0.5           0.0         0.0          80.0   \n",
       "\n",
       "    traffic_violations_avg  explored_states_avg  reward_cum_avg  actions_avg  \n",
       "50                     1.5                 25.6            7.55         22.3  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuning_data_rows = tuning_data[(tuning_data['traffic_violations_avg'] <= 5) & (tuning_data['success_perc'] >= 80)]\n",
    "tuning_data_rows.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So let's start looking for the row with the minimum value for the column *traffic_violations_avg*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "q_init_value               0.00\n",
       "alpha_rate                 0.25\n",
       "epsilon_rate               0.00\n",
       "gamma_rate                 1.00\n",
       "success_perc              30.00\n",
       "traffic_violations_avg     1.00\n",
       "explored_states_avg       20.60\n",
       "reward_cum_avg             5.95\n",
       "actions_avg               29.30\n",
       "Name: 29, dtype: float64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuning_data.loc[tuning_data['traffic_violations_avg'].idxmin()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The success percentage is not good, but let's do some more fine tuning to see if we can find a combination of parameters that minimizes number of traffic violations and maximizes the success.\n",
    "\n",
    "<h3>4.2. Second (fine tuned) Grid Search</h3>\n",
    "\n",
    "I will do a second grid search with these range of values:\n",
    "- *q_init_values*: 0.0, 1.0, 2.0 (3 values)\n",
    "- *alpha_rate*: 0.15, 0.20, 0.25, 0.30, 0.35 (5 values)\n",
    "- *epsilon_rate*: 0.00, 0.05, 0.10, 0.15, 0.20 (5 values)\n",
    "- *gamma_rate*: 0.80, 0.85, 0.90, 0.95, 1.00 (5 values)\n",
    "\n",
    "Let's analyze the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q_init_value</th>\n",
       "      <th>alpha_rate</th>\n",
       "      <th>epsilon_rate</th>\n",
       "      <th>gamma_rate</th>\n",
       "      <th>success_perc</th>\n",
       "      <th>traffic_violations_avg</th>\n",
       "      <th>explored_states_avg</th>\n",
       "      <th>reward_cum_avg</th>\n",
       "      <th>actions_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>375.000000</td>\n",
       "      <td>375.000000</td>\n",
       "      <td>375.000000</td>\n",
       "      <td>375.000000</td>\n",
       "      <td>375.000000</td>\n",
       "      <td>375.000000</td>\n",
       "      <td>375.000000</td>\n",
       "      <td>375.000000</td>\n",
       "      <td>375.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>28.666667</td>\n",
       "      <td>4.536000</td>\n",
       "      <td>27.204533</td>\n",
       "      <td>2.255867</td>\n",
       "      <td>26.415467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.817587</td>\n",
       "      <td>0.070805</td>\n",
       "      <td>0.070805</td>\n",
       "      <td>0.070805</td>\n",
       "      <td>22.981819</td>\n",
       "      <td>2.219941</td>\n",
       "      <td>3.479275</td>\n",
       "      <td>4.843244</td>\n",
       "      <td>4.183470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>13.700000</td>\n",
       "      <td>-6.550000</td>\n",
       "      <td>12.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>25.300000</td>\n",
       "      <td>-1.200000</td>\n",
       "      <td>23.850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>27.500000</td>\n",
       "      <td>1.350000</td>\n",
       "      <td>26.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>5.950000</td>\n",
       "      <td>29.500000</td>\n",
       "      <td>4.975000</td>\n",
       "      <td>29.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>11.300000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>25.150000</td>\n",
       "      <td>36.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       q_init_value  alpha_rate  epsilon_rate  gamma_rate  success_perc  \\\n",
       "count    375.000000  375.000000    375.000000  375.000000    375.000000   \n",
       "mean       1.000000    0.250000      0.100000    0.900000     28.666667   \n",
       "std        0.817587    0.070805      0.070805    0.070805     22.981819   \n",
       "min        0.000000    0.150000      0.000000    0.800000      0.000000   \n",
       "25%        0.000000    0.200000      0.050000    0.850000     10.000000   \n",
       "50%        1.000000    0.250000      0.100000    0.900000     20.000000   \n",
       "75%        2.000000    0.300000      0.150000    0.950000     40.000000   \n",
       "max        2.000000    0.350000      0.200000    1.000000    100.000000   \n",
       "\n",
       "       traffic_violations_avg  explored_states_avg  reward_cum_avg  \\\n",
       "count              375.000000           375.000000      375.000000   \n",
       "mean                 4.536000            27.204533        2.255867   \n",
       "std                  2.219941             3.479275        4.843244   \n",
       "min                  0.500000            13.700000       -6.550000   \n",
       "25%                  2.900000            25.300000       -1.200000   \n",
       "50%                  4.500000            27.500000        1.350000   \n",
       "75%                  5.950000            29.500000        4.975000   \n",
       "max                 11.300000            39.000000       25.150000   \n",
       "\n",
       "       actions_avg  \n",
       "count   375.000000  \n",
       "mean     26.415467  \n",
       "std       4.183470  \n",
       "min      12.900000  \n",
       "25%      23.850000  \n",
       "50%      26.900000  \n",
       "75%      29.100000  \n",
       "max      36.000000  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuning_data_2 = pd.read_csv(\"smartcab/qlearn_agent_tuning_results2.csv\", index_col=0)\n",
    "tuning_data_2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q_init_value</th>\n",
       "      <th>alpha_rate</th>\n",
       "      <th>epsilon_rate</th>\n",
       "      <th>gamma_rate</th>\n",
       "      <th>success_perc</th>\n",
       "      <th>traffic_violations_avg</th>\n",
       "      <th>explored_states_avg</th>\n",
       "      <th>reward_cum_avg</th>\n",
       "      <th>actions_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.80</td>\n",
       "      <td>50.0</td>\n",
       "      <td>9.7</td>\n",
       "      <td>28.2</td>\n",
       "      <td>4.15</td>\n",
       "      <td>23.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.85</td>\n",
       "      <td>50.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>35.4</td>\n",
       "      <td>9.25</td>\n",
       "      <td>24.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.90</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>12.45</td>\n",
       "      <td>26.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.95</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>25.7</td>\n",
       "      <td>7.30</td>\n",
       "      <td>32.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>70.0</td>\n",
       "      <td>7.3</td>\n",
       "      <td>22.8</td>\n",
       "      <td>0.70</td>\n",
       "      <td>17.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   q_init_value  alpha_rate  epsilon_rate  gamma_rate  success_perc  \\\n",
       "0           0.0        0.15           0.0        0.80          50.0   \n",
       "1           0.0        0.15           0.0        0.85          50.0   \n",
       "2           0.0        0.15           0.0        0.90          20.0   \n",
       "3           0.0        0.15           0.0        0.95          10.0   \n",
       "4           0.0        0.15           0.0        1.00          70.0   \n",
       "\n",
       "   traffic_violations_avg  explored_states_avg  reward_cum_avg  actions_avg  \n",
       "0                     9.7                 28.2            4.15         23.1  \n",
       "1                     3.5                 35.4            9.25         24.9  \n",
       "2                     1.0                 20.0           12.45         26.5  \n",
       "3                     1.1                 25.7            7.30         32.4  \n",
       "4                     7.3                 22.8            0.70         17.9  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuning_data_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "q_init_value               0.00\n",
       "alpha_rate                 0.75\n",
       "epsilon_rate               0.75\n",
       "gamma_rate                 1.00\n",
       "success_perc              20.00\n",
       "traffic_violations_avg     4.00\n",
       "explored_states_avg       31.80\n",
       "reward_cum_avg            -0.85\n",
       "actions_avg               24.70\n",
       "Name: 94, dtype: float64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuning_data.loc[tuning_data_2['success_perc'].idxmax()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>And the winner is...</h4>\n",
    "\n",
    "The **RewardAgent** has a poor success percentage so let's discard it.\n",
    "\n",
    "The difference between **SuccessAgent** and **ActionsAgent** is minimal. But the **SuccessAgent** has a slightly better accumulated reward average. So I will choose **SuccessAgent** as the winner.\n",
    "\n",
    "The parameter values for **SuccessAgent** are: **alpha_rate = 0.555556**, **epsilon_rate = 0.000000**, **gamma rate = 0.666667**."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
