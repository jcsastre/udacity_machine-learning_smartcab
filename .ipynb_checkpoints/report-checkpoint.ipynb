{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Self-Driving Agent Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Implementation of a Basic Driving Agent\n",
    "\n",
    "As starting task, we will move the smartcab around the environment using a random approach. The set of possible actions will be: None, forward, left, right. The deadline will be set to false, but this doesn't mean that smartcab has an infinite number of moves as can see on code of the file **smartcab/environment.py** (but will increase a lot the number of moves available).\n",
    "\n",
    "The code corresponding to this agent can be found on the class **RandomAgent** at the file **smartcab/agents.py**.\n",
    "\n",
    "Observations from simulation:\n",
    "\n",
    "1. Normally the smartcab action is not optimal, but normally reaches the destination because has a lot of moves available to reach the destination.\n",
    "2. The environment  doesn't allow any agent to execute and action that violates traffic rules, but a strong negative reward is applied."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Inform the Driving Agent\n",
    "\n",
    "The next task  is to identify a set of states that are appropriate for modeling the smartcab and environment. \n",
    "\n",
    "All the information we receive come from the environment and the planner.\n",
    "\n",
    "Sensing the environment provide us with these inputs:\n",
    "\n",
    "- light:\n",
    "    - Possible values: Red / Green\n",
    "- oncoming:\n",
    "    - Possible values: None / Forward / Right / Left\n",
    "    - Indicates if there is a car oncoming and the action wants to execute.\n",
    "- right:\n",
    "    - Possible values: None / Forward / Right / Left\n",
    "    - Indicates if there is a car approaching from the right oncoming and \n",
    "    the action wants to execute.\n",
    "- left:\n",
    "    - Possible values: None / Forward / Right / Left\n",
    "    - Indicates if there is a car approaching from the left oncoming and \n",
    "    the action wants to execute.\n",
    "\n",
    "Also from the environment we can obtain the deadline, that is the number of remaining moves to reach the destination.\n",
    "\n",
    "The planner provides next_waypoint, with these possible values: Forward, Right and Left.\n",
    "\n",
    "For representing the state we will use: **next_waypoint**, **light**, **oncoming**, **right** and **left**.\n",
    "\n",
    "Having in mind we use *next_waypoint*, is not very useful to also use *deadline*. Also *deadline* will increase considerably the number of possible states, and would penalize the Q-Learning implementation.\n",
    "\n",
    "The information from *light*, *oncoming*, *right* and *left* can help Q-Learning to avoid traffic violations. The information from *next_waypoint* can help Q-Learning to reach the destination as soon as possible.\n",
    " \n",
    "Having in mind the properties used for the state, and possible values for each of these, the total number of different states are: 3 x 2 x 4 x 4 x 4. This means a total of 384 states at a given time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Implement a Q-Learning Driving Agent\n",
    "\n",
    "The third task is to implement the Q-Learning algorithm for the driving agent. The code corresponding to this agent can be found on the class **QLearningAgent** at the file **smartcab/agents.py**.\n",
    "\n",
    "The core of the algorithm is a simple value iteration update. It assumes the old value and makes a correction based on the new information (Source: [Wikipedia](https://en.wikipedia.org/wiki/Q-learning)):\n",
    "\n",
    "![](images/qlearn.png)\n",
    "\n",
    "Before proceeding to the simulation, some parameter values should be set.\n",
    "\n",
    "In the formula shown above, two contants can be seen:\n",
    "- **alpha_rate (α)** or **learning rate**: Determines to what extent the newly acquired information will override the old information.\n",
    "- **gamma rate (γ)** or **discount factor**: Determines the importance of future rewards.\n",
    "\n",
    "Another important parameter when *QLearnAgent* should choose an action is the **epsilon_rate (ε)** or **exploration rate**. This parameter determines when to explore new states, or when to exploit already learn information.\n",
    "\n",
    "Finally another important value is the **Q init-value**, that is the value assigned to initialize the *Q matrix*. Please, notice that in the code I don't make a static initialization. Instead, in the method **get_q_value** I return **self.q_init_value** if no value for the key is found:\n",
    "\n",
    "~~~~\n",
    "def get_q_value(self, state, action):\n",
    "    key = (state, action)\n",
    "    return self.q_matrix.get(key, self.q_init_value)\n",
    "~~~~\n",
    "\n",
    "The param **self.q_init_value** can be set on the parameters of the *QLearnAgent* constructor.\n",
    "\n",
    "In my first attempt I will try with a very *exploratory* *QLearnAgent*. I will assign these values: *alpha_rate = 0.7*, *gamma rate = 0.5*, *epsilon_rate = 0.9* and *Q init-value = 10*.\n",
    "\n",
    "The simulation will be executed 100 times, with enforce_deadline to True. Some coded has been create to generate stats that I will analyze."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Analysis of generated data {#section}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_q_first = pd.read_csv(\"smartcab/main_q-agent_first_stats.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The generated stats consist on a table containing 100 rows (one by simulation round), and 6 columns:\n",
    "- **simulation_round**: The round number of the simulation.\n",
    "- **success**: True if the agent reached the destination.\n",
    "- **cum_reward**: The accumulated reward in that simulation.\n",
    "- **explored_states_cum**: The accumulated number of states explored.\n",
    "- **traffic_violations_count**: The traffic violations that occurred in that simulation.\n",
    "- **actions_count**: The actions taken in that simulation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Let's explore the 10 first rounds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>simulation_round</th>\n",
       "      <th>success</th>\n",
       "      <th>cum_reward</th>\n",
       "      <th>explored_states_cum</th>\n",
       "      <th>traffic_violations_count</th>\n",
       "      <th>actions_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>-6.5</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>3.5</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>29</td>\n",
       "      <td>7</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>4.5</td>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>-9.5</td>\n",
       "      <td>31</td>\n",
       "      <td>12</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "      <td>3.5</td>\n",
       "      <td>31</td>\n",
       "      <td>8</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "      <td>-2.5</td>\n",
       "      <td>32</td>\n",
       "      <td>7</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>35</td>\n",
       "      <td>8</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "      <td>-3.5</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>39</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   simulation_round success  cum_reward  explored_states_cum  \\\n",
       "0                 1    True        -6.5                   10   \n",
       "1                 2    True         3.5                   21   \n",
       "2                 3   False        -9.0                   29   \n",
       "3                 4   False         4.5                   31   \n",
       "4                 5   False        -9.5                   31   \n",
       "5                 6   False         3.5                   31   \n",
       "6                 7   False        -2.5                   32   \n",
       "7                 8   False       -11.0                   35   \n",
       "8                 9   False        -3.5                   36   \n",
       "9                10   False        -5.0                   39   \n",
       "\n",
       "   traffic_violations_count  actions_count  \n",
       "0                         5             16  \n",
       "1                         5             16  \n",
       "2                         7             30  \n",
       "3                         5             20  \n",
       "4                        12             35  \n",
       "5                         8             30  \n",
       "6                         7             25  \n",
       "7                         8             40  \n",
       "8                         7             25  \n",
       "9                        10             25  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_q_first.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that normally doesn't have success and commits a lot of traffic violations. The accumulated reward is normally negative. The explored states increases as rounds are done.\n",
    "\n",
    "Let's see now the 10 last iterations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>simulation_round</th>\n",
       "      <th>success</th>\n",
       "      <th>cum_reward</th>\n",
       "      <th>explored_states_cum</th>\n",
       "      <th>traffic_violations_count</th>\n",
       "      <th>actions_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>91</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>110</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>92</td>\n",
       "      <td>False</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>110</td>\n",
       "      <td>9</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>93</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>111</td>\n",
       "      <td>6</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>94</td>\n",
       "      <td>False</td>\n",
       "      <td>0.5</td>\n",
       "      <td>111</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>95</td>\n",
       "      <td>False</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>111</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96</td>\n",
       "      <td>False</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>112</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97</td>\n",
       "      <td>True</td>\n",
       "      <td>7.0</td>\n",
       "      <td>112</td>\n",
       "      <td>6</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98</td>\n",
       "      <td>False</td>\n",
       "      <td>-7.5</td>\n",
       "      <td>112</td>\n",
       "      <td>12</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99</td>\n",
       "      <td>False</td>\n",
       "      <td>10.5</td>\n",
       "      <td>112</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100</td>\n",
       "      <td>False</td>\n",
       "      <td>-12.5</td>\n",
       "      <td>112</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    simulation_round success  cum_reward  explored_states_cum  \\\n",
       "90                91   False         2.0                  110   \n",
       "91                92   False        -4.5                  110   \n",
       "92                93   False         1.0                  111   \n",
       "93                94   False         0.5                  111   \n",
       "94                95   False        -4.0                  111   \n",
       "95                96   False        -2.0                  112   \n",
       "96                97    True         7.0                  112   \n",
       "97                98   False        -7.5                  112   \n",
       "98                99   False        10.5                  112   \n",
       "99               100   False       -12.5                  112   \n",
       "\n",
       "    traffic_violations_count  actions_count  \n",
       "90                         7             20  \n",
       "91                         9             25  \n",
       "92                         6             30  \n",
       "93                         5             20  \n",
       "94                         5             20  \n",
       "95                         7             20  \n",
       "96                         6             24  \n",
       "97                        12             40  \n",
       "98                         3             20  \n",
       "99                        10             30  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_q_first.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We see more or less the same behaviour that in the first rounds, but the number of new states explored has increased a lot.\n",
    "\n",
    "I didn't notice many changes with respect to the *RandomAgent*. The *exploratory nature* of our *QLearnAgent* causes that his behaviour in the first 100 rounds is more or less the same than the *RandomAgent*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Improve the Q-Learning Driving Agent\n",
    "\n",
    "Now let's tune the values for the **Q init value**, the **learning rate (alpha)**, **the discount factor (gamma)** and the **exploration rate (epsilon)**.\n",
    "\n",
    "I will use *Grid Search* technique to tune these parameters.\n",
    "\n",
    "### 4.1. Grid Search\n",
    "\n",
    "I will do a *Grid Search* with these range of values:\n",
    "- *q_init_values*: 0.0, 5.0, 10 (3 values)\n",
    "- *alpha_rate*: 0.00, 0.25, 0.50, 0.75, 1.00 (5 values)\n",
    "- *epsilon_rate*: 0.00, 0.25, 0.50, 0.75, 1.00 (5 values)\n",
    "- *gamma_rate*: 0.00, 0.25, 0.50, 0.75, 1.00 (5 values)\n",
    "\n",
    "The total of combinations will be 375 (3x5x5x5). For each of the combinations, 100 simulations will be performed. This means 37.500 simulations will be done.\n",
    "\n",
    "For each combination of parameters we will aggregatte **ONLY** the results from the last 10 simulations of the *QLearningAgent*. These aggregated stats will be stored on a csv file, that we will analyze.\n",
    "\n",
    "The correspoding code to do the *Grid Search* and to generate the aggreggated stats can be found on **smartcab/main_qlearn_agent_tuning.py**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "tuning_data = pd.read_csv(\"smartcab/qlearn_agent_tuning_results_3_samples.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Let's see the first row to understand the columns contained:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q_init_value</th>\n",
       "      <th>alpha_rate</th>\n",
       "      <th>epsilon_rate</th>\n",
       "      <th>gamma_rate</th>\n",
       "      <th>success_perc</th>\n",
       "      <th>traffic_violations_avg</th>\n",
       "      <th>explored_states_avg</th>\n",
       "      <th>reward_cum_avg</th>\n",
       "      <th>actions_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>7.2</td>\n",
       "      <td>120.0</td>\n",
       "      <td>-2.15</td>\n",
       "      <td>27.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   q_init_value  alpha_rate  epsilon_rate  gamma_rate  success_perc  \\\n",
       "0           0.0         0.0           0.0         0.0          30.0   \n",
       "\n",
       "   traffic_violations_avg  explored_states_avg  reward_cum_avg  actions_avg  \n",
       "0                     7.2                120.0           -2.15         27.4  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuning_data.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each row corresponds to a simulation. The columns are:\n",
    "- **q_init_value**: The Q initial value used in that simulation.\n",
    "- **alpha_rate**: The alpha rate value used in that simulation.\n",
    "- **epsilon_rate**: The epsilon rate value used in that simulation.\n",
    "- **gamma_rate**: The gamma rate value used in that simulation.\n",
    "- **success_perc**: The percentage of success in that simulation (only for 10 last simulations done).\n",
    "- **traffic_violations_avg**: The traffic violation on average in that simulation (only for 10 last simulations done).\n",
    "- **explored_states_avg**: The explored states on average in that simulation (only for 10 last simulations done).\n",
    "- **reward_cum_avg**: The accumulated reward on average in that simulation (only for 10 last simulations done).\n",
    "- **actions_avg**: The actions done on average in that simulation (only for 10 last simulations done)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 4.2. An optimal policy\n",
    "\n",
    "Before looking for the optimal combination of parameters, we should define an optimal policy for the *QLearnAgent*.\n",
    "\n",
    "In my opinion an optimal policy for the smartcab is one that (in order of importance):\n",
    "1. Minimizes the number of traffic violations.\n",
    "2. Maximizes the success.\n",
    "\n",
    "We can also consider in the policy that the number of actions taken are the least possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 4.3. Looking for the best combination of parameters\n",
    "\n",
    "Let's start describing the data in the generated stats:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q_init_value</th>\n",
       "      <th>alpha_rate</th>\n",
       "      <th>epsilon_rate</th>\n",
       "      <th>gamma_rate</th>\n",
       "      <th>success_perc</th>\n",
       "      <th>traffic_violations_avg</th>\n",
       "      <th>explored_states_avg</th>\n",
       "      <th>reward_cum_avg</th>\n",
       "      <th>actions_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>81.000000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>81.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>20.617284</td>\n",
       "      <td>6.454321</td>\n",
       "      <td>96.527160</td>\n",
       "      <td>-1.064815</td>\n",
       "      <td>26.695062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.107919</td>\n",
       "      <td>0.410792</td>\n",
       "      <td>0.410792</td>\n",
       "      <td>0.410792</td>\n",
       "      <td>19.896336</td>\n",
       "      <td>3.013928</td>\n",
       "      <td>11.978178</td>\n",
       "      <td>4.228559</td>\n",
       "      <td>4.466428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>63.100000</td>\n",
       "      <td>-11.300000</td>\n",
       "      <td>6.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>6.100000</td>\n",
       "      <td>88.200000</td>\n",
       "      <td>-3.350000</td>\n",
       "      <td>24.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>7.300000</td>\n",
       "      <td>96.800000</td>\n",
       "      <td>-1.850000</td>\n",
       "      <td>27.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>8.600000</td>\n",
       "      <td>105.600000</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>29.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>11.100000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>12.550000</td>\n",
       "      <td>36.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       q_init_value  alpha_rate  epsilon_rate  gamma_rate  success_perc  \\\n",
       "count     81.000000   81.000000     81.000000   81.000000     81.000000   \n",
       "mean       5.000000    0.500000      0.500000    0.500000     20.617284   \n",
       "std        4.107919    0.410792      0.410792    0.410792     19.896336   \n",
       "min        0.000000    0.000000      0.000000    0.000000      0.000000   \n",
       "25%        0.000000    0.000000      0.000000    0.000000     10.000000   \n",
       "50%        5.000000    0.500000      0.500000    0.500000     20.000000   \n",
       "75%       10.000000    1.000000      1.000000    1.000000     20.000000   \n",
       "max       10.000000    1.000000      1.000000    1.000000    100.000000   \n",
       "\n",
       "       traffic_violations_avg  explored_states_avg  reward_cum_avg  \\\n",
       "count               81.000000            81.000000       81.000000   \n",
       "mean                 6.454321            96.527160       -1.064815   \n",
       "std                  3.013928            11.978178        4.228559   \n",
       "min                  0.000000            63.100000      -11.300000   \n",
       "25%                  6.100000            88.200000       -3.350000   \n",
       "50%                  7.300000            96.800000       -1.850000   \n",
       "75%                  8.600000           105.600000       -0.050000   \n",
       "max                 11.100000           120.000000       12.550000   \n",
       "\n",
       "       actions_avg  \n",
       "count    81.000000  \n",
       "mean     26.695062  \n",
       "std       4.466428  \n",
       "min       6.600000  \n",
       "25%      24.000000  \n",
       "50%      27.500000  \n",
       "75%      29.500000  \n",
       "max      36.500000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuning_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The minimum *traffic_violations_avg* is 0.0, the maximum for *success_perc* is 100% and the minimum for *actions_avg* is 6.6.\n",
    "\n",
    "Let's look for rows where *traffic_violations_avg <= 1* and *success_perc >= 90*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q_init_value</th>\n",
       "      <th>alpha_rate</th>\n",
       "      <th>epsilon_rate</th>\n",
       "      <th>gamma_rate</th>\n",
       "      <th>success_perc</th>\n",
       "      <th>traffic_violations_avg</th>\n",
       "      <th>explored_states_avg</th>\n",
       "      <th>reward_cum_avg</th>\n",
       "      <th>actions_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>67.9</td>\n",
       "      <td>10.8</td>\n",
       "      <td>13.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    q_init_value  alpha_rate  epsilon_rate  gamma_rate  success_perc  \\\n",
       "10           0.0         0.5           0.0         0.5         100.0   \n",
       "\n",
       "    traffic_violations_avg  explored_states_avg  reward_cum_avg  actions_avg  \n",
       "10                     0.1                 67.9            10.8         13.6  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuning_data_rows = tuning_data[(tuning_data['traffic_violations_avg'] <= 1) & (tuning_data['success_perc'] >= 90)]\n",
    "tuning_data_rows.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the row 10 we can see that in the 10 last simulations done, the **success_perc=100** and **traffic_violations_avg=0.1**. We can also see that **actions_avg=13.6**.\n",
    "\n",
    "It seems that the price to pay for minimize *traffic_violations_avg* is being far from the minimum *actions_avg* .\n",
    "\n",
    "So based in my criteria for an optimal policy, the parameter values to use are:\n",
    "- *q_init_value* = 0.0\n",
    "- *alpha_rate* = 0.5\n",
    "- *epsilon_rate* = 0.0\n",
    "- *gamma rate* = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 4.4. How these combination of parameters influence QLearnAgent behaviour\n",
    "\n",
    "To proceed to the analysis, let's generate detailed stats for a *QLearnAgent* using these values for parameters.\n",
    "\n",
    "In **smartcab/main_qlearn_agent_tuned.py** we execute 100 simulations and store the stats on a cvs file. The data generated follows the same pattern that data generated on \n",
    "[section 3.1](###3.1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stats_tuned = pd.read_csv(\"smartcab/stats_tuned_qlearn_agent.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4.1. *epsilon_rate* and *q_init_value*\n",
    "\n",
    "The *epsilon_rate=0.0* determines that the *QLearningAgent* will always try to exploit what he has already learn. Also a *q_init_value = 0.0* means that the *QLearningAgent* will be very conservative from the very beginning. \n",
    "\n",
    "The combination of these two parameters determines that the *QLearningAgent* will leave soon to explore new states. Let's visualize this behaviour:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"vega-embed\" id=\"055988ce-00c1-4dbc-af3f-db2b133d96de\"></div>\n",
       "\n",
       "<style>\n",
       ".vega-embed svg, .vega-embed canvas {\n",
       "  border: 1px dotted gray;\n",
       "}\n",
       "\n",
       ".vega-embed .vega-actions a {\n",
       "  margin-right: 6px;\n",
       "}\n",
       "</style>\n"
      ]
     },
     "metadata": {
      "jupyter-vega": "#055988ce-00c1-4dbc-af3f-db2b133d96de"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "var spec = {\"data\": {\"values\": [{\"success\": true, \"explored_states_cum\": 8, \"cum_reward\": 1.5, \"traffic_violations_count\": 3, \"simulation_round\": 1, \"actions_count\": 9}, {\"success\": false, \"explored_states_cum\": 18, \"cum_reward\": -10.0, \"traffic_violations_count\": 8, \"simulation_round\": 2, \"actions_count\": 40}, {\"success\": false, \"explored_states_cum\": 23, \"cum_reward\": -6.0, \"traffic_violations_count\": 7, \"simulation_round\": 3, \"actions_count\": 30}, {\"success\": false, \"explored_states_cum\": 34, \"cum_reward\": -7.5, \"traffic_violations_count\": 10, \"simulation_round\": 4, \"actions_count\": 30}, {\"success\": false, \"explored_states_cum\": 37, \"cum_reward\": -3.5, \"traffic_violations_count\": 0, \"simulation_round\": 5, \"actions_count\": 20}, {\"success\": false, \"explored_states_cum\": 41, \"cum_reward\": 4.0, \"traffic_violations_count\": 0, \"simulation_round\": 6, \"actions_count\": 20}, {\"success\": false, \"explored_states_cum\": 41, \"cum_reward\": 21.0, \"traffic_violations_count\": 2, \"simulation_round\": 7, \"actions_count\": 40}, {\"success\": false, \"explored_states_cum\": 41, \"cum_reward\": 11.0, \"traffic_violations_count\": 0, \"simulation_round\": 8, \"actions_count\": 20}, {\"success\": false, \"explored_states_cum\": 41, \"cum_reward\": 20.5, \"traffic_violations_count\": 0, \"simulation_round\": 9, \"actions_count\": 30}, {\"success\": true, \"explored_states_cum\": 41, \"cum_reward\": 13.5, \"traffic_violations_count\": 0, \"simulation_round\": 10, \"actions_count\": 20}, {\"success\": false, \"explored_states_cum\": 44, \"cum_reward\": 12.0, \"traffic_violations_count\": 3, \"simulation_round\": 11, \"actions_count\": 25}, {\"success\": true, \"explored_states_cum\": 44, \"cum_reward\": 3.5, \"traffic_violations_count\": 0, \"simulation_round\": 12, \"actions_count\": 2}, {\"success\": true, \"explored_states_cum\": 44, \"cum_reward\": 7.5, \"traffic_violations_count\": 0, \"simulation_round\": 13, \"actions_count\": 14}, {\"success\": true, \"explored_states_cum\": 44, \"cum_reward\": 14.0, \"traffic_violations_count\": 0, \"simulation_round\": 14, \"actions_count\": 12}, {\"success\": true, \"explored_states_cum\": 44, \"cum_reward\": 8.0, \"traffic_violations_count\": 0, \"simulation_round\": 15, \"actions_count\": 14}, {\"success\": true, \"explored_states_cum\": 44, \"cum_reward\": 1.5, \"traffic_violations_count\": 0, \"simulation_round\": 16, \"actions_count\": 8}, {\"success\": false, \"explored_states_cum\": 45, \"cum_reward\": 18.5, \"traffic_violations_count\": 0, \"simulation_round\": 17, \"actions_count\": 30}, {\"success\": false, \"explored_states_cum\": 48, \"cum_reward\": 31.0, \"traffic_violations_count\": 2, \"simulation_round\": 18, \"actions_count\": 50}, {\"success\": true, \"explored_states_cum\": 48, \"cum_reward\": 6.0, \"traffic_violations_count\": 0, \"simulation_round\": 19, \"actions_count\": 10}, {\"success\": false, \"explored_states_cum\": 49, \"cum_reward\": 4.5, \"traffic_violations_count\": 0, \"simulation_round\": 20, \"actions_count\": 20}, {\"success\": true, \"explored_states_cum\": 50, \"cum_reward\": 5.5, \"traffic_violations_count\": 0, \"simulation_round\": 21, \"actions_count\": 11}, {\"success\": true, \"explored_states_cum\": 50, \"cum_reward\": 12.0, \"traffic_violations_count\": 0, \"simulation_round\": 22, \"actions_count\": 23}, {\"success\": true, \"explored_states_cum\": 50, \"cum_reward\": 8.0, \"traffic_violations_count\": 0, \"simulation_round\": 23, \"actions_count\": 9}, {\"success\": false, \"explored_states_cum\": 51, \"cum_reward\": 28.0, \"traffic_violations_count\": 1, \"simulation_round\": 24, \"actions_count\": 45}, {\"success\": true, \"explored_states_cum\": 51, \"cum_reward\": 9.0, \"traffic_violations_count\": 0, \"simulation_round\": 25, \"actions_count\": 12}, {\"success\": true, \"explored_states_cum\": 52, \"cum_reward\": 15.0, \"traffic_violations_count\": 0, \"simulation_round\": 26, \"actions_count\": 24}, {\"success\": true, \"explored_states_cum\": 53, \"cum_reward\": 21.5, \"traffic_violations_count\": 0, \"simulation_round\": 27, \"actions_count\": 21}, {\"success\": true, \"explored_states_cum\": 53, \"cum_reward\": 13.5, \"traffic_violations_count\": 0, \"simulation_round\": 28, \"actions_count\": 14}, {\"success\": true, \"explored_states_cum\": 54, \"cum_reward\": 13.5, \"traffic_violations_count\": 0, \"simulation_round\": 29, \"actions_count\": 15}, {\"success\": false, \"explored_states_cum\": 56, \"cum_reward\": 5.5, \"traffic_violations_count\": 1, \"simulation_round\": 30, \"actions_count\": 40}, {\"success\": true, \"explored_states_cum\": 57, \"cum_reward\": 15.0, \"traffic_violations_count\": 0, \"simulation_round\": 31, \"actions_count\": 29}, {\"success\": true, \"explored_states_cum\": 58, \"cum_reward\": 19.0, \"traffic_violations_count\": 0, \"simulation_round\": 32, \"actions_count\": 34}, {\"success\": true, \"explored_states_cum\": 58, \"cum_reward\": 3.5, \"traffic_violations_count\": 0, \"simulation_round\": 33, \"actions_count\": 9}, {\"success\": true, \"explored_states_cum\": 58, \"cum_reward\": 10.0, \"traffic_violations_count\": 0, \"simulation_round\": 34, \"actions_count\": 8}, {\"success\": true, \"explored_states_cum\": 58, \"cum_reward\": 10.5, \"traffic_violations_count\": 1, \"simulation_round\": 35, \"actions_count\": 13}, {\"success\": true, \"explored_states_cum\": 59, \"cum_reward\": 16.0, \"traffic_violations_count\": 0, \"simulation_round\": 36, \"actions_count\": 19}, {\"success\": false, \"explored_states_cum\": 59, \"cum_reward\": 35.5, \"traffic_violations_count\": 0, \"simulation_round\": 37, \"actions_count\": 50}, {\"success\": true, \"explored_states_cum\": 59, \"cum_reward\": 9.0, \"traffic_violations_count\": 0, \"simulation_round\": 38, \"actions_count\": 20}, {\"success\": true, \"explored_states_cum\": 60, \"cum_reward\": 15.5, \"traffic_violations_count\": 0, \"simulation_round\": 39, \"actions_count\": 20}, {\"success\": false, \"explored_states_cum\": 60, \"cum_reward\": 11.5, \"traffic_violations_count\": 0, \"simulation_round\": 40, \"actions_count\": 20}, {\"success\": true, \"explored_states_cum\": 60, \"cum_reward\": 18.0, \"traffic_violations_count\": 0, \"simulation_round\": 41, \"actions_count\": 19}, {\"success\": true, \"explored_states_cum\": 60, \"cum_reward\": 10.0, \"traffic_violations_count\": 0, \"simulation_round\": 42, \"actions_count\": 13}, {\"success\": true, \"explored_states_cum\": 61, \"cum_reward\": 10.0, \"traffic_violations_count\": 0, \"simulation_round\": 43, \"actions_count\": 19}, {\"success\": false, \"explored_states_cum\": 61, \"cum_reward\": 15.0, \"traffic_violations_count\": 0, \"simulation_round\": 44, \"actions_count\": 20}, {\"success\": true, \"explored_states_cum\": 61, \"cum_reward\": 11.0, \"traffic_violations_count\": 1, \"simulation_round\": 45, \"actions_count\": 16}, {\"success\": true, \"explored_states_cum\": 61, \"cum_reward\": 14.5, \"traffic_violations_count\": 0, \"simulation_round\": 46, \"actions_count\": 30}, {\"success\": true, \"explored_states_cum\": 61, \"cum_reward\": 10.0, \"traffic_violations_count\": 0, \"simulation_round\": 47, \"actions_count\": 12}, {\"success\": false, \"explored_states_cum\": 63, \"cum_reward\": 26.5, \"traffic_violations_count\": 1, \"simulation_round\": 48, \"actions_count\": 35}, {\"success\": true, \"explored_states_cum\": 63, \"cum_reward\": 6.0, \"traffic_violations_count\": 0, \"simulation_round\": 49, \"actions_count\": 12}, {\"success\": false, \"explored_states_cum\": 63, \"cum_reward\": 26.0, \"traffic_violations_count\": 0, \"simulation_round\": 50, \"actions_count\": 35}, {\"success\": false, \"explored_states_cum\": 65, \"cum_reward\": 22.0, \"traffic_violations_count\": 0, \"simulation_round\": 51, \"actions_count\": 35}, {\"success\": true, \"explored_states_cum\": 65, \"cum_reward\": 11.5, \"traffic_violations_count\": 0, \"simulation_round\": 52, \"actions_count\": 19}, {\"success\": true, \"explored_states_cum\": 65, \"cum_reward\": 8.0, \"traffic_violations_count\": 0, \"simulation_round\": 53, \"actions_count\": 6}, {\"success\": true, \"explored_states_cum\": 65, \"cum_reward\": 16.0, \"traffic_violations_count\": 0, \"simulation_round\": 54, \"actions_count\": 20}, {\"success\": false, \"explored_states_cum\": 65, \"cum_reward\": 11.0, \"traffic_violations_count\": 0, \"simulation_round\": 55, \"actions_count\": 20}, {\"success\": true, \"explored_states_cum\": 65, \"cum_reward\": 13.5, \"traffic_violations_count\": 0, \"simulation_round\": 56, \"actions_count\": 10}, {\"success\": false, \"explored_states_cum\": 65, \"cum_reward\": 5.5, \"traffic_violations_count\": 1, \"simulation_round\": 57, \"actions_count\": 20}, {\"success\": false, \"explored_states_cum\": 68, \"cum_reward\": 6.0, \"traffic_violations_count\": 3, \"simulation_round\": 58, \"actions_count\": 20}, {\"success\": true, \"explored_states_cum\": 68, \"cum_reward\": 3.5, \"traffic_violations_count\": 0, \"simulation_round\": 59, \"actions_count\": 2}, {\"success\": true, \"explored_states_cum\": 69, \"cum_reward\": 10.5, \"traffic_violations_count\": 1, \"simulation_round\": 60, \"actions_count\": 11}, {\"success\": false, \"explored_states_cum\": 69, \"cum_reward\": 32.0, \"traffic_violations_count\": 0, \"simulation_round\": 61, \"actions_count\": 45}, {\"success\": true, \"explored_states_cum\": 69, \"cum_reward\": 10.0, \"traffic_violations_count\": 0, \"simulation_round\": 62, \"actions_count\": 4}, {\"success\": true, \"explored_states_cum\": 69, \"cum_reward\": 16.0, \"traffic_violations_count\": 0, \"simulation_round\": 63, \"actions_count\": 19}, {\"success\": false, \"explored_states_cum\": 69, \"cum_reward\": 20.5, \"traffic_violations_count\": 0, \"simulation_round\": 64, \"actions_count\": 35}, {\"success\": true, \"explored_states_cum\": 69, \"cum_reward\": 13.5, \"traffic_violations_count\": 0, \"simulation_round\": 65, \"actions_count\": 20}, {\"success\": false, \"explored_states_cum\": 69, \"cum_reward\": 28.0, \"traffic_violations_count\": 0, \"simulation_round\": 66, \"actions_count\": 40}, {\"success\": true, \"explored_states_cum\": 69, \"cum_reward\": 10.0, \"traffic_violations_count\": 0, \"simulation_round\": 67, \"actions_count\": 9}, {\"success\": true, \"explored_states_cum\": 69, \"cum_reward\": 12.0, \"traffic_violations_count\": 0, \"simulation_round\": 68, \"actions_count\": 16}, {\"success\": true, \"explored_states_cum\": 69, \"cum_reward\": 24.5, \"traffic_violations_count\": 0, \"simulation_round\": 69, \"actions_count\": 34}, {\"success\": true, \"explored_states_cum\": 70, \"cum_reward\": 10.5, \"traffic_violations_count\": 1, \"simulation_round\": 70, \"actions_count\": 17}, {\"success\": true, \"explored_states_cum\": 70, \"cum_reward\": 8.0, \"traffic_violations_count\": 0, \"simulation_round\": 71, \"actions_count\": 6}, {\"success\": false, \"explored_states_cum\": 70, \"cum_reward\": 22.5, \"traffic_violations_count\": 0, \"simulation_round\": 72, \"actions_count\": 35}, {\"success\": true, \"explored_states_cum\": 70, \"cum_reward\": 14.0, \"traffic_violations_count\": 0, \"simulation_round\": 73, \"actions_count\": 14}, {\"success\": false, \"explored_states_cum\": 70, \"cum_reward\": 26.5, \"traffic_violations_count\": 1, \"simulation_round\": 74, \"actions_count\": 40}, {\"success\": true, \"explored_states_cum\": 71, \"cum_reward\": 12.5, \"traffic_violations_count\": 1, \"simulation_round\": 75, \"actions_count\": 20}, {\"success\": true, \"explored_states_cum\": 71, \"cum_reward\": 7.5, \"traffic_violations_count\": 0, \"simulation_round\": 76, \"actions_count\": 11}, {\"success\": true, \"explored_states_cum\": 71, \"cum_reward\": 6.0, \"traffic_violations_count\": 0, \"simulation_round\": 77, \"actions_count\": 4}, {\"success\": false, \"explored_states_cum\": 72, \"cum_reward\": 12.5, \"traffic_violations_count\": 0, \"simulation_round\": 78, \"actions_count\": 30}, {\"success\": true, \"explored_states_cum\": 72, \"cum_reward\": 10.0, \"traffic_violations_count\": 0, \"simulation_round\": 79, \"actions_count\": 15}, {\"success\": false, \"explored_states_cum\": 73, \"cum_reward\": 8.5, \"traffic_violations_count\": 1, \"simulation_round\": 80, \"actions_count\": 20}, {\"success\": true, \"explored_states_cum\": 73, \"cum_reward\": 5.0, \"traffic_violations_count\": 0, \"simulation_round\": 81, \"actions_count\": 12}, {\"success\": false, \"explored_states_cum\": 74, \"cum_reward\": 12.5, \"traffic_violations_count\": 0, \"simulation_round\": 82, \"actions_count\": 20}, {\"success\": true, \"explored_states_cum\": 74, \"cum_reward\": 5.0, \"traffic_violations_count\": 1, \"simulation_round\": 83, \"actions_count\": 4}, {\"success\": true, \"explored_states_cum\": 74, \"cum_reward\": 8.0, \"traffic_violations_count\": 0, \"simulation_round\": 84, \"actions_count\": 5}, {\"success\": true, \"explored_states_cum\": 74, \"cum_reward\": 10.0, \"traffic_violations_count\": 0, \"simulation_round\": 85, \"actions_count\": 11}, {\"success\": true, \"explored_states_cum\": 74, \"cum_reward\": 13.5, \"traffic_violations_count\": 0, \"simulation_round\": 86, \"actions_count\": 21}, {\"success\": false, \"explored_states_cum\": 75, \"cum_reward\": 12.0, \"traffic_violations_count\": 1, \"simulation_round\": 87, \"actions_count\": 20}, {\"success\": true, \"explored_states_cum\": 75, \"cum_reward\": 0.0, \"traffic_violations_count\": 0, \"simulation_round\": 88, \"actions_count\": -1}, {\"success\": true, \"explored_states_cum\": 75, \"cum_reward\": 8.0, \"traffic_violations_count\": 0, \"simulation_round\": 89, \"actions_count\": 11}, {\"success\": true, \"explored_states_cum\": 75, \"cum_reward\": 10.0, \"traffic_violations_count\": 0, \"simulation_round\": 90, \"actions_count\": 11}, {\"success\": true, \"explored_states_cum\": 75, \"cum_reward\": 7.5, \"traffic_violations_count\": 0, \"simulation_round\": 91, \"actions_count\": 12}, {\"success\": true, \"explored_states_cum\": 75, \"cum_reward\": 11.0, \"traffic_violations_count\": 0, \"simulation_round\": 92, \"actions_count\": 17}, {\"success\": true, \"explored_states_cum\": 75, \"cum_reward\": 7.5, \"traffic_violations_count\": 0, \"simulation_round\": 93, \"actions_count\": 9}, {\"success\": true, \"explored_states_cum\": 75, \"cum_reward\": 10.0, \"traffic_violations_count\": 0, \"simulation_round\": 94, \"actions_count\": 5}, {\"success\": false, \"explored_states_cum\": 75, \"cum_reward\": 19.0, \"traffic_violations_count\": 0, \"simulation_round\": 95, \"actions_count\": 20}, {\"success\": true, \"explored_states_cum\": 75, \"cum_reward\": 10.0, \"traffic_violations_count\": 0, \"simulation_round\": 96, \"actions_count\": 10}, {\"success\": true, \"explored_states_cum\": 75, \"cum_reward\": 10.0, \"traffic_violations_count\": 0, \"simulation_round\": 97, \"actions_count\": 8}, {\"success\": false, \"explored_states_cum\": 75, \"cum_reward\": 26.0, \"traffic_violations_count\": 0, \"simulation_round\": 98, \"actions_count\": 30}, {\"success\": false, \"explored_states_cum\": 75, \"cum_reward\": 5.5, \"traffic_violations_count\": 0, \"simulation_round\": 99, \"actions_count\": 20}, {\"success\": true, \"explored_states_cum\": 75, \"cum_reward\": 23.0, \"traffic_violations_count\": 0, \"simulation_round\": 100, \"actions_count\": 31}]}, \"encoding\": {\"y\": {\"field\": \"explored_states_cum\", \"type\": \"quantitative\"}, \"x\": {\"field\": \"simulation_round\", \"type\": \"quantitative\"}}, \"config\": {\"cell\": {\"width\": 500, \"height\": 350}}, \"mark\": \"line\"};\n",
       "var selector = \"#055988ce-00c1-4dbc-af3f-db2b133d96de\";\n",
       "var type = \"vega-lite\";\n",
       "\n",
       "var output_area = this;\n",
       "require(['nbextensions/jupyter-vega/index'], function(vega) {\n",
       "  vega.render(selector, spec, type, output_area);\n",
       "}, function (err) {\n",
       "  if (err.requireType !== 'scripterror') {\n",
       "    throw(err);\n",
       "  }\n",
       "});\n"
      ]
     },
     "metadata": {
      "jupyter-vega": "#055988ce-00c1-4dbc-af3f-db2b133d96de"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from altair import Chart\n",
    "\n",
    "Chart(stats_tuned).mark_line().encode(\n",
    "    x= 'simulation_round',\n",
    "    y='explored_states_cum'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected abount round 10 onwards the number of explored states increses much slower that at the initial rounds. It seems that explored will stabilize around 60-65, but a test with more than 100 round simulations is needed to confirm this trend."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Other important aspect is the the number of possible locations for the smartcab:\n",
    "\n",
    "![](images/grid.png)\n",
    "\n",
    "There are 48 possible locations (8 x 6 grid). In the simulation there are 4 smartcabs in total.\n",
    "\n",
    "This means that there are very few chances for our *QLearnAgent* to learn situations where the actions taken by the other cars are important to avoid traffic violations. So it will need many simulations to fully learn to avoid traffic violations, because will have few chances to learn to correctly interact with other agents.\n",
    "\n",
    "Let's visualize the correlation between *simulation_rounds* and *traffic_violations_count*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"vega-embed\" id=\"955372c8-9f17-420c-a291-758a9d8738b0\"></div>\n",
       "\n",
       "<style>\n",
       ".vega-embed svg, .vega-embed canvas {\n",
       "  border: 1px dotted gray;\n",
       "}\n",
       "\n",
       ".vega-embed .vega-actions a {\n",
       "  margin-right: 6px;\n",
       "}\n",
       "</style>\n"
      ]
     },
     "metadata": {
      "jupyter-vega": "#955372c8-9f17-420c-a291-758a9d8738b0"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "var spec = {\"data\": {\"values\": [{\"success\": false, \"explored_states_cum\": 17, \"cum_reward\": -5.0, \"traffic_violations_count\": 10, \"simulation_round\": 1, \"actions_count\": 30}, {\"success\": false, \"explored_states_cum\": 21, \"cum_reward\": -8.0, \"traffic_violations_count\": 10, \"simulation_round\": 2, \"actions_count\": 20}, {\"success\": false, \"explored_states_cum\": 26, \"cum_reward\": -7.0, \"traffic_violations_count\": 11, \"simulation_round\": 3, \"actions_count\": 25}, {\"success\": false, \"explored_states_cum\": 30, \"cum_reward\": -11.5, \"traffic_violations_count\": 5, \"simulation_round\": 4, \"actions_count\": 45}, {\"success\": false, \"explored_states_cum\": 33, \"cum_reward\": -4.5, \"traffic_violations_count\": 6, \"simulation_round\": 5, \"actions_count\": 45}, {\"success\": false, \"explored_states_cum\": 33, \"cum_reward\": 0.0, \"traffic_violations_count\": 2, \"simulation_round\": 6, \"actions_count\": 20}, {\"success\": true, \"explored_states_cum\": 33, \"cum_reward\": -3.0, \"traffic_violations_count\": 5, \"simulation_round\": 7, \"actions_count\": 5}, {\"success\": false, \"explored_states_cum\": 33, \"cum_reward\": 2.0, \"traffic_violations_count\": 0, \"simulation_round\": 8, \"actions_count\": 30}, {\"success\": false, \"explored_states_cum\": 33, \"cum_reward\": 2.0, \"traffic_violations_count\": 6, \"simulation_round\": 9, \"actions_count\": 25}, {\"success\": true, \"explored_states_cum\": 35, \"cum_reward\": 13.5, \"traffic_violations_count\": 4, \"simulation_round\": 10, \"actions_count\": 18}, {\"success\": true, \"explored_states_cum\": 35, \"cum_reward\": 6.0, \"traffic_violations_count\": 0, \"simulation_round\": 11, \"actions_count\": 4}, {\"success\": true, \"explored_states_cum\": 40, \"cum_reward\": 3.0, \"traffic_violations_count\": 5, \"simulation_round\": 12, \"actions_count\": 10}, {\"success\": true, \"explored_states_cum\": 40, \"cum_reward\": -2.0, \"traffic_violations_count\": 8, \"simulation_round\": 13, \"actions_count\": 12}, {\"success\": true, \"explored_states_cum\": 40, \"cum_reward\": 10.0, \"traffic_violations_count\": 0, \"simulation_round\": 14, \"actions_count\": 15}, {\"success\": true, \"explored_states_cum\": 40, \"cum_reward\": 10.0, \"traffic_violations_count\": 0, \"simulation_round\": 15, \"actions_count\": 9}, {\"success\": true, \"explored_states_cum\": 41, \"cum_reward\": 11.0, \"traffic_violations_count\": 1, \"simulation_round\": 16, \"actions_count\": 26}, {\"success\": true, \"explored_states_cum\": 41, \"cum_reward\": 15.5, \"traffic_violations_count\": 0, \"simulation_round\": 17, \"actions_count\": 23}, {\"success\": true, \"explored_states_cum\": 41, \"cum_reward\": 6.0, \"traffic_violations_count\": 0, \"simulation_round\": 18, \"actions_count\": 6}, {\"success\": true, \"explored_states_cum\": 42, \"cum_reward\": 17.5, \"traffic_violations_count\": 4, \"simulation_round\": 19, \"actions_count\": 26}, {\"success\": true, \"explored_states_cum\": 42, \"cum_reward\": 10.0, \"traffic_violations_count\": 0, \"simulation_round\": 20, \"actions_count\": 17}, {\"success\": true, \"explored_states_cum\": 42, \"cum_reward\": 10.0, \"traffic_violations_count\": 0, \"simulation_round\": 21, \"actions_count\": 15}, {\"success\": true, \"explored_states_cum\": 42, \"cum_reward\": 10.0, \"traffic_violations_count\": 0, \"simulation_round\": 22, \"actions_count\": 9}, {\"success\": true, \"explored_states_cum\": 43, \"cum_reward\": 20.0, \"traffic_violations_count\": 0, \"simulation_round\": 23, \"actions_count\": 19}, {\"success\": true, \"explored_states_cum\": 43, \"cum_reward\": 18.0, \"traffic_violations_count\": 0, \"simulation_round\": 24, \"actions_count\": 15}, {\"success\": true, \"explored_states_cum\": 43, \"cum_reward\": 12.0, \"traffic_violations_count\": 0, \"simulation_round\": 25, \"actions_count\": 12}, {\"success\": true, \"explored_states_cum\": 44, \"cum_reward\": 8.0, \"traffic_violations_count\": 0, \"simulation_round\": 26, \"actions_count\": 3}, {\"success\": true, \"explored_states_cum\": 44, \"cum_reward\": 6.0, \"traffic_violations_count\": 0, \"simulation_round\": 27, \"actions_count\": 15}, {\"success\": true, \"explored_states_cum\": 44, \"cum_reward\": 8.0, \"traffic_violations_count\": 0, \"simulation_round\": 28, \"actions_count\": 19}, {\"success\": true, \"explored_states_cum\": 44, \"cum_reward\": 6.0, \"traffic_violations_count\": 0, \"simulation_round\": 29, \"actions_count\": 2}, {\"success\": true, \"explored_states_cum\": 44, \"cum_reward\": 6.0, \"traffic_violations_count\": 0, \"simulation_round\": 30, \"actions_count\": 10}, {\"success\": true, \"explored_states_cum\": 44, \"cum_reward\": 8.0, \"traffic_violations_count\": 0, \"simulation_round\": 31, \"actions_count\": 9}, {\"success\": true, \"explored_states_cum\": 44, \"cum_reward\": 6.0, \"traffic_violations_count\": 0, \"simulation_round\": 32, \"actions_count\": 9}, {\"success\": true, \"explored_states_cum\": 44, \"cum_reward\": 14.0, \"traffic_violations_count\": 0, \"simulation_round\": 33, \"actions_count\": 14}, {\"success\": true, \"explored_states_cum\": 44, \"cum_reward\": 10.0, \"traffic_violations_count\": 0, \"simulation_round\": 34, \"actions_count\": 15}, {\"success\": true, \"explored_states_cum\": 44, \"cum_reward\": 10.0, \"traffic_violations_count\": 0, \"simulation_round\": 35, \"actions_count\": 17}, {\"success\": true, \"explored_states_cum\": 45, \"cum_reward\": 12.0, \"traffic_violations_count\": 0, \"simulation_round\": 36, \"actions_count\": 14}, {\"success\": true, \"explored_states_cum\": 45, \"cum_reward\": 8.0, \"traffic_violations_count\": 0, \"simulation_round\": 37, \"actions_count\": 7}, {\"success\": true, \"explored_states_cum\": 45, \"cum_reward\": 16.0, \"traffic_violations_count\": 0, \"simulation_round\": 38, \"actions_count\": 17}, {\"success\": true, \"explored_states_cum\": 45, \"cum_reward\": 12.0, \"traffic_violations_count\": 0, \"simulation_round\": 39, \"actions_count\": 11}, {\"success\": true, \"explored_states_cum\": 45, \"cum_reward\": 12.0, \"traffic_violations_count\": 0, \"simulation_round\": 40, \"actions_count\": 10}, {\"success\": true, \"explored_states_cum\": 45, \"cum_reward\": 11.5, \"traffic_violations_count\": 0, \"simulation_round\": 41, \"actions_count\": 9}, {\"success\": true, \"explored_states_cum\": 45, \"cum_reward\": 10.0, \"traffic_violations_count\": 0, \"simulation_round\": 42, \"actions_count\": 9}, {\"success\": true, \"explored_states_cum\": 45, \"cum_reward\": 8.0, \"traffic_violations_count\": 0, \"simulation_round\": 43, \"actions_count\": 5}, {\"success\": true, \"explored_states_cum\": 46, \"cum_reward\": 12.0, \"traffic_violations_count\": 0, \"simulation_round\": 44, \"actions_count\": 8}, {\"success\": true, \"explored_states_cum\": 46, \"cum_reward\": 6.0, \"traffic_violations_count\": 0, \"simulation_round\": 45, \"actions_count\": 11}, {\"success\": true, \"explored_states_cum\": 46, \"cum_reward\": 14.0, \"traffic_violations_count\": 0, \"simulation_round\": 46, \"actions_count\": 23}, {\"success\": true, \"explored_states_cum\": 46, \"cum_reward\": 12.0, \"traffic_violations_count\": 0, \"simulation_round\": 47, \"actions_count\": 14}, {\"success\": true, \"explored_states_cum\": 46, \"cum_reward\": 10.0, \"traffic_violations_count\": 0, \"simulation_round\": 48, \"actions_count\": 9}, {\"success\": true, \"explored_states_cum\": 47, \"cum_reward\": 9.0, \"traffic_violations_count\": 1, \"simulation_round\": 49, \"actions_count\": 15}, {\"success\": true, \"explored_states_cum\": 47, \"cum_reward\": 10.0, \"traffic_violations_count\": 0, \"simulation_round\": 50, \"actions_count\": 9}, {\"success\": true, \"explored_states_cum\": 47, \"cum_reward\": 6.0, \"traffic_violations_count\": 0, \"simulation_round\": 51, \"actions_count\": 6}, {\"success\": true, \"explored_states_cum\": 48, \"cum_reward\": 7.0, \"traffic_violations_count\": 1, \"simulation_round\": 52, \"actions_count\": 13}, {\"success\": true, \"explored_states_cum\": 48, \"cum_reward\": 9.5, \"traffic_violations_count\": 0, \"simulation_round\": 53, \"actions_count\": 10}, {\"success\": true, \"explored_states_cum\": 50, \"cum_reward\": 23.0, \"traffic_violations_count\": 0, \"simulation_round\": 54, \"actions_count\": 34}, {\"success\": true, \"explored_states_cum\": 50, \"cum_reward\": 8.0, \"traffic_violations_count\": 0, \"simulation_round\": 55, \"actions_count\": 9}, {\"success\": true, \"explored_states_cum\": 51, \"cum_reward\": 13.5, \"traffic_violations_count\": 0, \"simulation_round\": 56, \"actions_count\": 14}, {\"success\": true, \"explored_states_cum\": 51, \"cum_reward\": 10.0, \"traffic_violations_count\": 0, \"simulation_round\": 57, \"actions_count\": 12}, {\"success\": true, \"explored_states_cum\": 52, \"cum_reward\": 14.5, \"traffic_violations_count\": 1, \"simulation_round\": 58, \"actions_count\": 23}, {\"success\": true, \"explored_states_cum\": 52, \"cum_reward\": 6.0, \"traffic_violations_count\": 0, \"simulation_round\": 59, \"actions_count\": 7}, {\"success\": true, \"explored_states_cum\": 52, \"cum_reward\": 6.0, \"traffic_violations_count\": 0, \"simulation_round\": 60, \"actions_count\": 11}, {\"success\": true, \"explored_states_cum\": 52, \"cum_reward\": 18.0, \"traffic_violations_count\": 0, \"simulation_round\": 61, \"actions_count\": 15}, {\"success\": true, \"explored_states_cum\": 53, \"cum_reward\": 9.5, \"traffic_violations_count\": 0, \"simulation_round\": 62, \"actions_count\": 14}, {\"success\": true, \"explored_states_cum\": 54, \"cum_reward\": 5.5, \"traffic_violations_count\": 0, \"simulation_round\": 63, \"actions_count\": 7}, {\"success\": true, \"explored_states_cum\": 56, \"cum_reward\": 7.0, \"traffic_violations_count\": 1, \"simulation_round\": 64, \"actions_count\": 19}, {\"success\": true, \"explored_states_cum\": 56, \"cum_reward\": 13.5, \"traffic_violations_count\": 2, \"simulation_round\": 65, \"actions_count\": 26}, {\"success\": true, \"explored_states_cum\": 56, \"cum_reward\": 8.0, \"traffic_violations_count\": 0, \"simulation_round\": 66, \"actions_count\": 15}, {\"success\": true, \"explored_states_cum\": 56, \"cum_reward\": 6.0, \"traffic_violations_count\": 0, \"simulation_round\": 67, \"actions_count\": 12}, {\"success\": true, \"explored_states_cum\": 56, \"cum_reward\": 12.0, \"traffic_violations_count\": 0, \"simulation_round\": 68, \"actions_count\": 23}, {\"success\": true, \"explored_states_cum\": 56, \"cum_reward\": 11.0, \"traffic_violations_count\": 1, \"simulation_round\": 69, \"actions_count\": 15}, {\"success\": true, \"explored_states_cum\": 56, \"cum_reward\": 6.0, \"traffic_violations_count\": 0, \"simulation_round\": 70, \"actions_count\": 12}, {\"success\": true, \"explored_states_cum\": 56, \"cum_reward\": 10.0, \"traffic_violations_count\": 0, \"simulation_round\": 71, \"actions_count\": 9}, {\"success\": true, \"explored_states_cum\": 56, \"cum_reward\": 9.5, \"traffic_violations_count\": 0, \"simulation_round\": 72, \"actions_count\": 15}, {\"success\": true, \"explored_states_cum\": 57, \"cum_reward\": 10.0, \"traffic_violations_count\": 0, \"simulation_round\": 73, \"actions_count\": 11}, {\"success\": true, \"explored_states_cum\": 57, \"cum_reward\": 10.0, \"traffic_violations_count\": 0, \"simulation_round\": 74, \"actions_count\": 14}, {\"success\": true, \"explored_states_cum\": 57, \"cum_reward\": 8.0, \"traffic_violations_count\": 0, \"simulation_round\": 75, \"actions_count\": 8}, {\"success\": true, \"explored_states_cum\": 57, \"cum_reward\": 7.5, \"traffic_violations_count\": 0, \"simulation_round\": 76, \"actions_count\": 4}, {\"success\": true, \"explored_states_cum\": 57, \"cum_reward\": 10.0, \"traffic_violations_count\": 0, \"simulation_round\": 77, \"actions_count\": 11}, {\"success\": true, \"explored_states_cum\": 57, \"cum_reward\": 14.0, \"traffic_violations_count\": 0, \"simulation_round\": 78, \"actions_count\": 14}, {\"success\": true, \"explored_states_cum\": 57, \"cum_reward\": 8.0, \"traffic_violations_count\": 0, \"simulation_round\": 79, \"actions_count\": 17}, {\"success\": true, \"explored_states_cum\": 57, \"cum_reward\": 10.0, \"traffic_violations_count\": 0, \"simulation_round\": 80, \"actions_count\": 19}, {\"success\": true, \"explored_states_cum\": 57, \"cum_reward\": 8.0, \"traffic_violations_count\": 0, \"simulation_round\": 81, \"actions_count\": 6}, {\"success\": true, \"explored_states_cum\": 57, \"cum_reward\": 6.0, \"traffic_violations_count\": 0, \"simulation_round\": 82, \"actions_count\": 11}, {\"success\": true, \"explored_states_cum\": 59, \"cum_reward\": 8.0, \"traffic_violations_count\": 0, \"simulation_round\": 83, \"actions_count\": 15}, {\"success\": true, \"explored_states_cum\": 59, \"cum_reward\": 16.0, \"traffic_violations_count\": 0, \"simulation_round\": 84, \"actions_count\": 11}, {\"success\": true, \"explored_states_cum\": 59, \"cum_reward\": 15.5, \"traffic_violations_count\": 0, \"simulation_round\": 85, \"actions_count\": 22}, {\"success\": true, \"explored_states_cum\": 59, \"cum_reward\": 16.0, \"traffic_violations_count\": 0, \"simulation_round\": 86, \"actions_count\": 13}, {\"success\": true, \"explored_states_cum\": 59, \"cum_reward\": 11.5, \"traffic_violations_count\": 0, \"simulation_round\": 87, \"actions_count\": 17}, {\"success\": true, \"explored_states_cum\": 59, \"cum_reward\": 16.0, \"traffic_violations_count\": 0, \"simulation_round\": 88, \"actions_count\": 15}, {\"success\": true, \"explored_states_cum\": 59, \"cum_reward\": 14.0, \"traffic_violations_count\": 0, \"simulation_round\": 89, \"actions_count\": 24}, {\"success\": true, \"explored_states_cum\": 59, \"cum_reward\": 18.0, \"traffic_violations_count\": 0, \"simulation_round\": 90, \"actions_count\": 19}, {\"success\": true, \"explored_states_cum\": 59, \"cum_reward\": 12.0, \"traffic_violations_count\": 0, \"simulation_round\": 91, \"actions_count\": 14}, {\"success\": true, \"explored_states_cum\": 59, \"cum_reward\": 16.0, \"traffic_violations_count\": 0, \"simulation_round\": 92, \"actions_count\": 20}, {\"success\": true, \"explored_states_cum\": 59, \"cum_reward\": 14.0, \"traffic_violations_count\": 0, \"simulation_round\": 93, \"actions_count\": 24}, {\"success\": true, \"explored_states_cum\": 60, \"cum_reward\": 10.0, \"traffic_violations_count\": 0, \"simulation_round\": 94, \"actions_count\": 9}, {\"success\": true, \"explored_states_cum\": 62, \"cum_reward\": 9.5, \"traffic_violations_count\": 0, \"simulation_round\": 95, \"actions_count\": 13}, {\"success\": true, \"explored_states_cum\": 62, \"cum_reward\": 6.0, \"traffic_violations_count\": 0, \"simulation_round\": 96, \"actions_count\": 3}, {\"success\": true, \"explored_states_cum\": 62, \"cum_reward\": 6.0, \"traffic_violations_count\": 0, \"simulation_round\": 97, \"actions_count\": 12}, {\"success\": true, \"explored_states_cum\": 62, \"cum_reward\": 8.0, \"traffic_violations_count\": 0, \"simulation_round\": 98, \"actions_count\": 5}, {\"success\": true, \"explored_states_cum\": 62, \"cum_reward\": 8.0, \"traffic_violations_count\": 0, \"simulation_round\": 99, \"actions_count\": 8}, {\"success\": true, \"explored_states_cum\": 62, \"cum_reward\": 5.0, \"traffic_violations_count\": 1, \"simulation_round\": 100, \"actions_count\": 3}]}, \"encoding\": {\"y\": {\"field\": \"traffic_violations_count\", \"type\": \"quantitative\"}, \"x\": {\"field\": \"simulation_round\", \"type\": \"quantitative\"}}, \"config\": {\"cell\": {\"width\": 500, \"height\": 350}}, \"mark\": \"line\"};\n",
       "var selector = \"#955372c8-9f17-420c-a291-758a9d8738b0\";\n",
       "var type = \"vega-lite\";\n",
       "\n",
       "var output_area = this;\n",
       "require(['nbextensions/jupyter-vega/index'], function(vega) {\n",
       "  vega.render(selector, spec, type, output_area);\n",
       "}, function (err) {\n",
       "  if (err.requireType !== 'scripterror') {\n",
       "    throw(err);\n",
       "  }\n",
       "});\n"
      ]
     },
     "metadata": {
      "jupyter-vega": "#955372c8-9f17-420c-a291-758a9d8738b0"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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"
     },
     "metadata": {
      "jupyter-vega": "#955372c8-9f17-420c-a291-758a9d8738b0"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from altair import Chart\n",
    "\n",
    "Chart(stats_tuned).mark_line().encode(\n",
    "    x= 'simulation_round',\n",
    "    y= 'traffic_violations_count'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected we can see that about round 60, the *QLearnAgent* still incurs on some traffic violations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4.2. *gamma_rate*\n",
    "\n",
    "As explained previously, *gamma_rate* determines the importance of future rewards. A *gamma_rate=0* causes that future rewards have no influence on the learned value. A *gamma_rate=1* causes that future rewards have a lot of influence on the learned value.\n",
    "\n",
    "Our state includes *next_waypoint* (provided by the *Planner*), and is the only information we have to reach the destination. So is important that our *QLearnAgent* learns that following *next_waypoint* is important. Going to the *next_waypoint* without traffic violations produces a reward of 2.00, and from time to time a reward of 12.00 is received because the destination has been reach (2.00 + 10.00).\n",
    "\n",
    "Also the next state depends on the movements of other agents, and from any state is possible to be transition to any of the other states, so this is a good reason to downplay future rewards.\n",
    "\n",
    "I our case *gamma_rate=0.5*, but probably tt does not have much influence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4.3. *alpha_rate*\n",
    "\n",
    "The *alpha_rate=0.5* makes sense, becauses the *QLearnAgent* learns that following the *next_waypoint* is good because normally receives a *R=2.00*, but from time to time it receives a *R=12.00*. But this is a little bit random, because the *next_waypoint* has no correlation with the distance to the destination. Just following *next_waypoint* as much as possible is good to reach the destination."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
