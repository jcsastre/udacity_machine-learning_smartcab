{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h1>Self-Driving Agent Report</h1>\n",
    "\n",
    "<h2>1. Implementation of a Basic Driving Agent</h2>\n",
    "\n",
    "As starting task, we will move the smartcab around the environment using a random approach. The set of possible actions will be: None, forward, left, right. The deadline will be set to false, but this doesn't mean that smartcab has an infinite number of moves as can see on code of the file *environment.py* (but will increase a lot the number of moves available).\n",
    "\n",
    "The code corresponding to this agent can be found on the class *RandomAgent* at the file *smartcab/agents.py*.\n",
    "\n",
    "Observations from simulation:\n",
    "\n",
    "1. Normally the smartcab action is not optimal, but normally reaches the destination because has a lot of moves available to reach the destination.\n",
    "2. The environment  doesn't allow any agent to execute and action that violates traffic rules, but a strong negative reward is applied.\n",
    "\n",
    "<h2>2. Inform the Driving Agent</h2>\n",
    "\n",
    "The next task  is to identify a set of states that are appropriate for modeling the smartcab and environment. \n",
    "\n",
    "All the information we receive come from the environment and the planner.\n",
    "\n",
    "Sensing the environment provide us with these inputs:\n",
    "\n",
    "- **light**\n",
    "    - Possible values: Red / Green\n",
    "- **oncoming**:\n",
    "    - Possible values: None / Forward / Right / Left\n",
    "    - Indicates if there is a car oncoming and the action wants to execute.\n",
    "- **right**:\n",
    "    - Possible values: None / Forward / Right / Left\n",
    "    - Indicates if there is a car approaching from the right oncoming and \n",
    "    the action wants to execute.\n",
    "- **left**:\n",
    "    - Possible values: None / Forward / Right / Left\n",
    "    - Indicates if there is a car approaching from the left oncoming and \n",
    "    the action wants to execute.\n",
    "\n",
    "Also from the environment we can obtain the **deadline** that the is number of remaining moves to reach the destination.\n",
    "\n",
    "The planner provides **next_waypoint** with these possible values: Forward, Right and Left.\n",
    "\n",
    "For representing the state we will use: **next_waypoint**, **light**, **oncoming**, **right** and **left**.\n",
    "\n",
    "Having in mind we use **next_waypoint**, is not very useful to also use **deadline**. Also **deadline** will increase considerably the number of possible states, and would penalize the Q-Learning implementation.\n",
    "\n",
    "The information from **light**, **oncoming**, **right** and **left** can help Q-Learning to avoid traffic violations. The information from **next_waypoint** can help Q-Learning to reach the destination as soon as possible.\n",
    " \n",
    "Having in mind the properties used for the state, and possible values for each of these, the total number of different states are: 3 x 2 x 4 x 4 x 4. This means a total of 384 states at a given time.\n",
    "\n",
    "<h2>Implement a Q-Learning Driving Agent</h2>\n",
    "\n",
    "The third task is to implement the Q-Learning algorithm for the driving agent. The code corresponding to this agent can be found on the class *QLearningAgent* at the file *smartcab/agents.py*.\n",
    "\n",
    "Before proceeding to the simulation, the values for three important constants should be assigned:\n",
    "- *alpha_rate (α)* or *learning rate*: Determines to what extent the newly acquired information will override the old information.\n",
    "- *epsilon_rate (ε)* or *exploration rate*: Determines when to explore or when to exploit the already learn information.\n",
    "- *gamma rate (γ)* or *discount factor*: Determines the importance of future rewards.\n",
    "\n",
    "We will execute 100 simulations with enforce_deadline to True. We will do our first attempt with these values for the constants:\n",
    "- *alpha_rate (α)* = 0.9\n",
    "- *epsilon_rate (ε)* = 0.1\n",
    "- *gamma rate (γ)* = 0.5.\n",
    "\n",
    "Let's analyze a scatter plot that correlates number of simulations executed (iterations) with size of the Q matrix:\n",
    "\n",
    "![](plots/qlearner_1_scatter_iterations_q-size.png)\n",
    "\n",
    "As we can see in the plot, as simulations are executed the number of values in Q matrix increases. At the beginning increases fast, but later increases slow. This is normal because the number of scenarios not visited decreases while simulations\n",
    "accumulate.\n",
    "\n",
    "Let's analyze a scatter plot that correlates number of iterations with accumulated reward for each of the iterations:\n",
    "\n",
    "![](plots/qlearner_1_scatter_iterations_cum-reward.png)\n",
    "\n",
    "We don't see that as the number of iterations increase the agent gets better accumulated rewards. Maybe the assigned values for the constants were poorly chosen.\n",
    "\n",
    "Now let's see the number of times q-learner agent has achieved the destination:\n",
    "- Success: 21 times\n",
    "- Fail: 79 times\n",
    "\n",
    "In the first section of this report we saw that the random agent normally was successfully, but we must consider that the deadline was set to false. To make a fairer comparison, lets compare with a random agent with deadline set to true.\n",
    "\n",
    "Let's see the number of times random agent has achieved the destination:\n",
    "- Success: 16 times\n",
    "- Fail: 84 times\n",
    "\n",
    "There is not too much difference between the success ratio of the *RandomAgent* and the *QLearningAgent*. As said previously maybe the values for the constants were poorly chosen. Other options are that perform 100 simulations are not enough for the \n",
    "*QLearningAgent*, or maybe the q-learn algorithm is bad implemented."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Improve the Q-Learning Driving Agent</h2>\n",
    "\n",
    "Now let's tune the values for *learning rate (alpha)*, *the discount factor (gamma)* and the *exploration rate (epsilon)*. \n",
    "\n",
    "We will perform many simulations with many combinations of these parameters, and the we will report the results to see what \n",
    "is the best combination.\n",
    "\n",
    "The results of the simulations will be stored on a csv file, that we will analyze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>alpha_rate</th>\n",
       "      <th>epsilon_rate</th>\n",
       "      <th>gamma_rate</th>\n",
       "      <th>successPerc</th>\n",
       "      <th>actionsAvg</th>\n",
       "      <th>cumRewardAvg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>125.000000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>125.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>23.048000</td>\n",
       "      <td>26.496000</td>\n",
       "      <td>-0.959440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>36.228442</td>\n",
       "      <td>0.354976</td>\n",
       "      <td>0.354976</td>\n",
       "      <td>0.354976</td>\n",
       "      <td>15.292764</td>\n",
       "      <td>2.752196</td>\n",
       "      <td>4.390346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>-12.740000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>31.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>-2.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>-2.005000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>93.000000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>-0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>124.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>16.125000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>alpha_rate</th>\n",
       "      <th>epsilon_rate</th>\n",
       "      <th>gamma_rate</th>\n",
       "      <th>successPerc</th>\n",
       "      <th>actionsAvg</th>\n",
       "      <th>cumRewardAvg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>125.000000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>125.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>23.048000</td>\n",
       "      <td>26.496000</td>\n",
       "      <td>-0.959440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>36.228442</td>\n",
       "      <td>0.354976</td>\n",
       "      <td>0.354976</td>\n",
       "      <td>0.354976</td>\n",
       "      <td>15.292764</td>\n",
       "      <td>2.752196</td>\n",
       "      <td>4.390346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>-12.740000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>31.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>-2.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>-2.005000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>93.000000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>-0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>124.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>16.125000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "tuning_data = pd.read_csv(\"smartcab/qlearn_agent_tuning_results.csv\")\n",
    "tuning_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the better success percentage has been 90%. This is really a good percentage, so we can discard a bad implementation of the Q algorithm. It seems I selected bad values for the parameters.\n",
    "\n",
    "Lets see the parameters values that correspond to a 90% success."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0      51.000\n",
       "alpha_rate       0.500\n",
       "epsilon_rate     0.000\n",
       "gamma_rate       0.250\n",
       "successPerc     90.000\n",
       "actionsAvg      15.000\n",
       "cumRewardAvg     9.925\n",
       "Name: 51, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuning_data.loc[tuning_data['successPerc'].idxmax()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values are:\n",
    "\n",
    "- *alpha_rate (α)* = 0.500\n",
    "- *epsilon_rate (ε)* = 0.000\n",
    "- *gamma rate (γ)* = 0.250\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
